#!/usr/bin/env python3
"""Generate route content registry from CSV."""

from __future__ import annotations

import csv
import json
import sys
from pathlib import Path

INPUT_CSV = Path("docs/output/enki-v1-sitemap-seo-template.csv")
OUTPUT_TS = Path("src/lib/route-content.generated.ts")

REQUIRED_COLUMNS = [
    "path_yolu",
    "baslik_h1",
    "seo_title",
    "seo_description",
    "description",
    "short_description",
    "micro_line",
    "indexing",
    "canonical",
]


def clean(value: str | None) -> str:
    return (value or "").strip()


def fail(message: str) -> None:
    print(f"[generate-route-content] {message}", file=sys.stderr)
    raise SystemExit(1)


def build_output(records: list[dict[str, str]]) -> str:
    lines: list[str] = []
    lines.append("// This file is auto-generated by scripts/generate-route-content.py.")
    lines.append("// Do not edit this file directly.")
    lines.append("")
    lines.append("export type RouteContent = {")
    lines.append("  path: string;")
    lines.append("  h1?: string;")
    lines.append("  seoTitle?: string;")
    lines.append("  seoDescription?: string;")
    lines.append("  description?: string;")
    lines.append("  shortDescription?: string;")
    lines.append("  microLine?: string;")
    lines.append("  canonical?: string;")
    lines.append("  indexing?: string;")
    lines.append("};")
    lines.append("")
    lines.append("export const ROUTE_CONTENT: Record<string, RouteContent> = {")

    for row in records:
        path = row["path"]
        lines.append(f"  {json.dumps(path)}: {{")
        lines.append(f"    path: {json.dumps(path)},")

        if row.get("h1"):
            lines.append(f"    h1: {json.dumps(row['h1'])},")
        if row.get("seoTitle"):
            lines.append(f"    seoTitle: {json.dumps(row['seoTitle'])},")
        if row.get("seoDescription"):
            lines.append(f"    seoDescription: {json.dumps(row['seoDescription'])},")
        if row.get("description"):
            lines.append(f"    description: {json.dumps(row['description'])},")
        if row.get("shortDescription"):
            lines.append(f"    shortDescription: {json.dumps(row['shortDescription'])},")
        if row.get("microLine"):
            lines.append(f"    microLine: {json.dumps(row['microLine'])},")
        if row.get("canonical"):
            lines.append(f"    canonical: {json.dumps(row['canonical'])},")
        if row.get("indexing"):
            lines.append(f"    indexing: {json.dumps(row['indexing'])},")

        lines.append("  },")

    lines.append("} as const;")
    lines.append("")
    return "\n".join(lines)


def main() -> None:
    if not INPUT_CSV.exists():
        fail(f"Input CSV not found: {INPUT_CSV}")

    with INPUT_CSV.open("r", encoding="utf-8-sig", newline="") as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames or []
        missing_columns = [name for name in REQUIRED_COLUMNS if name not in fieldnames]
        if missing_columns:
            fail(
                "Missing required CSV column(s): "
                + ", ".join(missing_columns)
            )

        records: list[dict[str, str]] = []
        seen_paths: set[str] = set()
        kesfet_paths: list[str] = []

        for row_number, row in enumerate(reader, start=2):
            path = clean(row.get("path_yolu"))
            if not path:
                continue

            if path in seen_paths:
                fail(f"Duplicate path_yolu at CSV line {row_number}: {path}")
            seen_paths.add(path)

            if path.startswith("/kesfet/"):
                kesfet_paths.append(path)

            canonical = clean(row.get("canonical")) or path
            record: dict[str, str] = {
                "path": path,
                "canonical": canonical,
            }

            h1 = clean(row.get("baslik_h1"))
            seo_title = clean(row.get("seo_title"))
            seo_description = clean(row.get("seo_description"))
            description = clean(row.get("description"))
            short_description = clean(row.get("short_description"))
            micro_line = clean(row.get("micro_line"))
            indexing = clean(row.get("indexing"))

            if h1:
                record["h1"] = h1
            if seo_title:
                record["seoTitle"] = seo_title
            if seo_description:
                record["seoDescription"] = seo_description
            if description:
                record["description"] = description
            if short_description:
                record["shortDescription"] = short_description
            if micro_line:
                record["microLine"] = micro_line
            if indexing:
                record["indexing"] = indexing

            records.append(record)

    if len(kesfet_paths) != 9:
        fail(
            "Expected 9 '/kesfet/' rows in CSV, found "
            f"{len(kesfet_paths)}"
        )

    OUTPUT_TS.parent.mkdir(parents=True, exist_ok=True)
    OUTPUT_TS.write_text(build_output(records), encoding="utf-8")
    print(f"[generate-route-content] Wrote {OUTPUT_TS} ({len(records)} routes)")


if __name__ == "__main__":
    main()
